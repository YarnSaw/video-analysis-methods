{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the modules\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# need to pad videos so they are all the same length (in number of frames). Util function for that, and run it here (run it once then we don't need it again)\n",
    "from frames import leastmostframes\n",
    "# least, most = leastmostframes('subset2/data')\n",
    "most = 76 # hard coded for speed. The function only really needs to be run whenever we add new videos to our dataset.\n",
    "\n",
    "# directory to load data to train on\n",
    "dataDirectory = \"subset2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the datasets for use\n",
    "\n",
    "# given a video id, return the greyscale version of the video\n",
    "def processID(Id):\n",
    "  global most\n",
    "  video = cv2.VideoCapture(f'{dataDirectory}/data/{Id}.webm')\n",
    "  greyScaleVideo = []\n",
    "\n",
    "  # read each frame, convert the frame data to greyscale & append to the new array to be returned.\n",
    "  newFrame, data = video.read()\n",
    "  while newFrame:\n",
    "    greyScaleVideo.append(cv2.cvtColor(data, cv2.COLOR_BGR2GRAY))\n",
    "    newFrame, data = video.read()\n",
    "  \n",
    "  # Appending additional frames of blackness \n",
    "  numBlackFrames = most - len(greyScaleVideo)\n",
    "  greyScaleVideo = np.concatenate([greyScaleVideo, np.zeros((numBlackFrames, *greyScaleVideo[0].shape))])\n",
    "  \n",
    "  return greyScaleVideo\n",
    "\n",
    "# training/validation data set json files (describes which videos belong to which category)\n",
    "with open(r'C:\\Users\\emily\\Documents\\video-analysis-methods\\subset2\\subset-train.json') as file:\n",
    "  trainingSetInfo = json.load(file)\n",
    "\n",
    "with open(r'C:\\Users\\emily\\Documents\\video-analysis-methods\\subset2\\subset-validation.json') as file:\n",
    "  validationSetInfo = json.load(file)\n",
    "\n",
    "classes = []\n",
    "for element in trainingSetInfo:\n",
    "  if element['template'] not in classes:\n",
    "    classes.append(element['template'])\n",
    "\n",
    "#custom dataset class. Allows us to load only the data to be used into memory, since the videos are otherwise way too large\n",
    "class somethingDataset(data.Dataset):\n",
    "  #setInfo for either the training or validation set. The object loaded in above, used to know which videos belong to each set\n",
    "  def __init__(self, setInfo):\n",
    "    self.setInfo = setInfo\n",
    "  \n",
    "  # how many elements to the dataset\n",
    "  def __len__(self):\n",
    "    return len(self.setInfo)\n",
    "\n",
    "  # called whenever an item needs to be retrieved from the dataset. Current implementation is to\n",
    "  # find the video at the given index, load that video/convert to greyscale, then return that + the class (which is the template string)\n",
    "  def __getitem__(self, index):\n",
    "    vid = self.setInfo[index]\n",
    "    video = processID(vid['id'])\n",
    "    label = vid['template']\n",
    "    index = classes.index(label)\n",
    "    label = np.zeros((len(classes)))\n",
    "    label[index] = 1\n",
    "    return video, label\n",
    "\n",
    "# prepare the dataloaders that will work with the dataset class to get the specific data we want when we request it.\n",
    "# the first argument is the dataset we want to use (training or validation). Shuffle is if we want to randomize the order\n",
    "# of the dataset, and num_workers allows for some multithreading (should speed things up, but if we notice problems we can remove\n",
    "# so it will be slower but all on 1 thread)\n",
    "trainDataLoader = data.DataLoader(somethingDataset(trainingSetInfo[:50]), batch_size=64, shuffle=True, num_workers=0)\n",
    "validationDataLoader = data.DataLoader(validationSetInfo, batch_size=64, shuffle=True, num_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very simple convolutional neural network class.\n",
    "class CNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__() # instantiate the pytorch module\n",
    "\n",
    "    # Layer 1: a 3d convolution\n",
    "    #                      greyscale (3 for rgb)   num filters\n",
    "    self.conv1 = nn.Conv3d(in_channels=1,          out_channels=5, kernel_size=(5,5,5))\n",
    "    self.relu1 = nn.ReLU()\n",
    "    self.maxpool1 = nn.MaxPool3d(kernel_size=(2,2), stride=(2,2))\n",
    "\n",
    "    # Layer 2: linear (hidden)\n",
    "    # PROBABLE ERROR: NOT SURE WHAT SIZE THE in_features OF fc1 SHOULD BE. RIGHT NOW IT IS 800 AS JUST 'SOME BIG NUMBER', BUT PROBABLY NEED TO BE CHANGED. \n",
    "    # check the size of the output of flatten in the forward function to determine what this should be\n",
    "    self.fc1 = nn.Linear(in_features=800, out_features=500)\n",
    "    self.relu3 = nn.ReLU()\n",
    "\n",
    "    # Layer 3: linear (output)\n",
    "    #                                  have 3 classes\n",
    "    self.fc2 = nn.Linear(in_features=500, out_features=3)\n",
    "    self.logSoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "  # forward function for the model. Training using backward propagation, with the backward function being handled by\n",
    "  # pytorch so we only need to create the forward.\n",
    "  def forward(self, x):\n",
    "    # Layer 1: 3d convolution + maxpool\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu1(x)\n",
    "    x = self.maxpool1(x)\n",
    "\n",
    "    # Layer 2: flatten the network, then use linear\n",
    "    x = torch.flatten(x,1)\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu3(x)\n",
    "\n",
    "    # Layer 3: linear with softmax for our output\n",
    "    x = self.fc2(x)\n",
    "    output = self.logSoftmax(x)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m     20\u001b[0m \u001b[39mfor\u001b[39;00m (x,y) \u001b[39min\u001b[39;00m trainDataLoader: \u001b[39m# x variable represents input data and y represents corresponding output \u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m   x, y \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39;49mto(device)  \u001b[39m# Moves input and output to specified device\u001b[39;00m\n\u001b[0;32m     22\u001b[0m   optimizer\u001b[39m.\u001b[39mzero_grad()              \u001b[39m# Sets the models gradients to zero for each iteration so previous doesnt affect current\u001b[39;00m\n\u001b[0;32m     23\u001b[0m   y_pred \u001b[39m=\u001b[39m model(x)                  \u001b[39m# COmputes models predicted output for input data\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "# Running the model\n",
    "\n",
    "\n",
    "device = 'cpu' # or 'cuda' in future\n",
    "model = CNN().to(device) # instantiate the CNN\n",
    "\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() # loss function \n",
    "\n",
    "# optimizer function (what we are using to minimize the loss) (Adam is essentially a better version of gradient descent)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train_loss_list = [] # we will want to keep a history of the loss values so we can plot it\n",
    "for epoch in range(EPOCHS):\n",
    "  train_loss = 0\n",
    "\n",
    "  model.train()\n",
    "  for (x,y) in trainDataLoader: # x variable represents input data and y represents corresponding output \n",
    "    x = x.to(device)  # Moves input and output to specified device\n",
    "    optimizer.zero_grad()              # Sets the models gradients to zero for each iteration so previous doesnt affect current\n",
    "    y_pred = model(x)                  # COmputes models predicted output for input data\n",
    "    loss = loss_fn(y_pred, y)          # Computes loss between predicted output and true output\n",
    "    loss.backward()                    # cOMPUTES GRADIENT\n",
    "    optimizer.step()                   # Updates models parameters\n",
    "    \n",
    "    #attempted error fixes: workers to 0, batch size from 64 to 1, trainingsetInfo[:500]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58a66d7bbf596cc668bce0ab9bea31c5eb558b2e4e3050de1ebd0ad57b8e47fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
